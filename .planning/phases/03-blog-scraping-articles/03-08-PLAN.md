---
phase: 03-blog-scraping-articles
plan: 08
type: execute
wave: 3
depends_on: ["03-06"]
files_modified:
  - server/lib/scraping.ts
  - server/inngest/functions/scrape-blog.ts
  - src/lib/server/scraping.ts
  - src/types/blog-projects.ts
  - src/types/articles.ts
  - src/components/projects/project-dialog.tsx
  - src/components/articles/scrape-button.tsx
  - src/routes/_authed/projects/$id.tsx
autonomous: true

must_haves:
  truths:
    - "Scrape Blog uses sitemap.xml to discover article URLs instead of RSS feed"
    - "Sitemap URL field replaces RSS URL in project settings and detail page"
    - "Scraping flow: sitemap first, then RSS fallback, then HTML fallback"
  artifacts:
    - path: "server/lib/scraping.ts"
      provides: "scrapeSitemap function that parses sitemap XML for article URLs"
      contains: "scrapeSitemap"
    - path: "server/inngest/functions/scrape-blog.ts"
      provides: "Updated scrape flow trying sitemap before RSS"
      contains: "scrape-sitemap"
    - path: "src/types/blog-projects.ts"
      provides: "sitemap_url field on BlogProject type"
      contains: "sitemap_url"
  key_links:
    - from: "server/inngest/functions/scrape-blog.ts"
      to: "server/lib/scraping.ts"
      via: "imports scrapeSitemap"
      pattern: "scrapeSitemap"
    - from: "src/components/articles/scrape-button.tsx"
      to: "src/lib/server/scraping.ts"
      via: "passes sitemap_url in scrape request"
      pattern: "sitemap_url"
---

<objective>
Replace RSS feed-based article discovery with sitemap.xml parsing. Sitemaps provide structured XML with all published URLs, improving article coverage and parse reliability over RSS feeds.

Purpose: Better article discovery — sitemaps list all pages (not just recent N like RSS), use standardized XML format, and are universally available on blog platforms.

Output: Updated scraping pipeline that tries sitemap first, falls back to RSS, then HTML. Project settings show sitemap URL instead of RSS URL.
</objective>

<execution_context>
@/Users/cweissteiner/.claude/get-shit-done/workflows/execute-plan.md
@/Users/cweissteiner/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/STATE.md
@server/lib/scraping.ts
@server/inngest/functions/scrape-blog.ts
@src/lib/server/scraping.ts
@src/types/blog-projects.ts
@src/types/articles.ts
@src/components/projects/project-dialog.tsx
@src/components/articles/scrape-button.tsx
@src/routes/_authed/projects/$id.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add sitemap_url column and update types</name>
  <files>
    src/types/blog-projects.ts
    src/types/articles.ts
  </files>
  <action>
    **1. Database migration** — Add `sitemap_url` column to `blog_projects` table via Supabase MCP:
    ```sql
    ALTER TABLE blog_projects ADD COLUMN sitemap_url TEXT;
    ```

    **2. Update `src/types/blog-projects.ts`** — Add `sitemap_url` field:
    - `BlogProject`: add `sitemap_url: string | null`
    - `BlogProjectInsert`: add `sitemap_url?: string | null`
    - `BlogProjectUpdate`: add `sitemap_url?: string | null`

    **3. Update `src/types/articles.ts`** — Update `ScrapeRequest`:
    - Replace `rss_url` with `sitemap_url` (keep `rss_url` as fallback):
      ```typescript
      export interface ScrapeRequest {
        blog_project_id: string
        blog_url: string
        sitemap_url?: string | null
        rss_url?: string | null
      }
      ```
    - Add `'sitemap'` to `ScrapeResponse.method` union type:
      ```typescript
      method: 'sitemap' | 'rss' | 'html' | 'single'
      ```
  </action>
  <verify>
    - `sitemap_url` column exists on `blog_projects` table
    - `BlogProject` type includes `sitemap_url: string | null`
    - `ScrapeRequest` includes `sitemap_url` field
    - `ScrapeResponse.method` includes `'sitemap'` option
  </verify>
  <done>
    Database column added, TypeScript types updated with sitemap_url support.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add scrapeSitemap function and update scraping flow</name>
  <files>
    server/lib/scraping.ts
    server/inngest/functions/scrape-blog.ts
    src/lib/server/scraping.ts
  </files>
  <action>
    **1. Add `scrapeSitemap()` to `server/lib/scraping.ts`:**

    ```typescript
    /**
     * Scrape sitemap.xml for article URLs
     */
    export async function scrapeSitemap(blogUrl: string, sitemapUrl?: string): Promise<ArticleData[]> {
      // Determine sitemap URL
      let url = sitemapUrl || new URL('/sitemap.xml', blogUrl).toString()

      const response = await fetch(url)
      if (!response.ok) {
        throw new Error(`Failed to fetch sitemap: ${response.status}`)
      }

      const xml = await response.text()
      const parser = new XMLParser({ ignoreAttributes: false, attributeNamePrefix: '@_' })
      const parsed = parser.parse(xml)

      // Handle sitemap index (contains references to other sitemaps)
      if (parsed.sitemapindex?.sitemap) {
        const sitemaps = Array.isArray(parsed.sitemapindex.sitemap)
          ? parsed.sitemapindex.sitemap
          : [parsed.sitemapindex.sitemap]

        const allArticles: ArticleData[] = []
        for (const sitemap of sitemaps) {
          const loc = sitemap.loc?.toString().trim()
          if (loc) {
            try {
              const childArticles = await scrapeSitemap(blogUrl, loc)
              allArticles.push(...childArticles)
            } catch {
              // Continue with next sitemap
            }
          }
        }
        return allArticles
      }

      // Handle regular urlset
      const rawUrls = parsed.urlset?.url
      if (!rawUrls) {
        throw new Error('No URLs found in sitemap')
      }

      const urls = Array.isArray(rawUrls) ? rawUrls : [rawUrls]

      // Filter to likely blog post URLs (exclude homepage, category, tag pages)
      const blogBaseUrl = new URL(blogUrl).origin
      const articleUrls = urls
        .map(entry => ({
          loc: entry.loc?.toString().trim(),
          lastmod: entry.lastmod?.toString().trim(),
        }))
        .filter(entry => {
          if (!entry.loc) return false
          // Exclude the homepage itself
          if (entry.loc === blogUrl || entry.loc === blogUrl + '/') return false
          // Must be on same domain
          if (!entry.loc.startsWith(blogBaseUrl)) return false
          return true
        })

      // Scrape each URL for article content
      const articles: ArticleData[] = []
      for (const entry of articleUrls) {
        try {
          const article = await scrapeSingleUrl(entry.loc!)
          // Use lastmod from sitemap if article has no publish date
          if (!article.published_at && entry.lastmod) {
            article.published_at = entry.lastmod
          }
          articles.push(article)
        } catch (error) {
          console.error(`Failed to scrape ${entry.loc}: ${String(error)}`)
        }
      }

      return articles
    }
    ```

    **2. Update `server/inngest/functions/scrape-blog.ts`** — Add sitemap as first scraping method:

    - Import `scrapeSitemap` from `../../lib/scraping`
    - Add `sitemap_url` to event data destructuring
    - Add Step 0 (before existing RSS step): try sitemap scraping
    - Only fall through to RSS if sitemap found no articles
    - Update method tracking: `'sitemap' | 'rss' | 'html'`

    Flow becomes:
    1. Try sitemap (`scrapeSitemap(blog_url, sitemap_url)`)
    2. If no articles → try RSS (`scrapeRss(blog_url, rss_url)`)
    3. If no articles → try HTML (`scrapeHtml(blog_url)`)

    **3. Update `src/lib/server/scraping.ts`** — Update `scrapeBlogFn` input validator:
    - Add `sitemap_url?: string | null` to input validator type
    - Pass `sitemap_url` in the Inngest event data
  </action>
  <verify>
    - `scrapeSitemap` function exists and is exported from `server/lib/scraping.ts`
    - `scrape-blog.ts` tries sitemap before RSS
    - `scrapeBlogFn` accepts and passes `sitemap_url`
    - `npx tsc --noEmit -p tsconfig.server.json` passes
  </verify>
  <done>
    Sitemap scraping function implemented. Scrape flow: sitemap → RSS → HTML.
  </done>
</task>

<task type="auto">
  <name>Task 3: Update UI to use sitemap_url</name>
  <files>
    src/components/projects/project-dialog.tsx
    src/components/articles/scrape-button.tsx
    src/routes/_authed/projects/$id.tsx
  </files>
  <action>
    **1. Update `src/components/projects/project-dialog.tsx`:**
    - Replace `rss_url` form field with `sitemap_url`
    - Update schema: `rss_url` → `sitemap_url`
    - Update form default values and reset logic
    - Update label: "RSS URL" → "Sitemap URL"
    - Update placeholder: "https://myblog.com/feed" → "https://myblog.com/sitemap.xml"
    - Update manual validation in `onSubmit` for `sitemap_url`
    - Update mutation call: pass `sitemap_url` instead of `rss_url`

    **2. Update `src/components/articles/scrape-button.tsx`:**
    - Rename prop `rssUrl` → `sitemapUrl`
    - Update `ScrapeButtonProps` interface
    - Pass `sitemap_url: sitemapUrl` in mutate call instead of `rss_url: rssUrl`

    **3. Update `src/routes/_authed/projects/$id.tsx`:**
    - Replace `project.rss_url` display with `project.sitemap_url`
    - Update labels: "RSS:" → "Sitemap:"
    - Update "RSS: Not configured" → "Sitemap: Not configured"
    - Update `ScrapeButton` prop: `rssUrl={project.rss_url}` → `sitemapUrl={project.sitemap_url}`
  </action>
  <verify>
    - Project dialog shows "Sitemap URL" field instead of "RSS URL"
    - Scrape button passes `sitemap_url` in request
    - Project detail page shows "Sitemap:" label
    - `npm run build` passes with no TypeScript errors
  </verify>
  <done>
    UI updated to use sitemap_url throughout. Project settings, scrape button, and detail page all reference sitemap.
  </done>
</task>

</tasks>

<verification>
1. `npm run build` passes with zero errors
2. Project dialog shows "Sitemap URL" field in edit mode
3. Project detail page shows "Sitemap:" label with URL or "Not configured"
4. Scrape blog triggers sitemap-based discovery first
5. `scrapeSitemap` function correctly parses sitemap XML and sitemap index files
6. Fallback chain works: sitemap → RSS → HTML
</verification>

<success_criteria>
- Sitemap-based scraping replaces RSS as primary article discovery method
- UI shows sitemap URL instead of RSS URL throughout
- Scraping fallback chain preserved (sitemap → RSS → HTML)
- All TypeScript compilation passes
</success_criteria>

<output>
After completion, create `.planning/phases/03-blog-scraping-articles/03-08-SUMMARY.md`
</output>
